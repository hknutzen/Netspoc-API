#!/bin/bash

usage () {
    echo "Usage: $0 [user@]remote worker-command" >&2
    exit 1
}

[ $# -eq 2 ] || usage

# Username and hostname or IP of remote server, where jobs arrive.
# Used by ssh and scp.
REMOTE=$1

# Program that processes jobs, one by one.
# Path to job is given as argument, errors are written to STDERR.
WORKER=$2

# Wait that many seconds before retry after error.
WAIT_ERR=10

# Append content of file 'err' together with time stamp to file 'log'.
log () {
    echo -n 'Date: ' >>log
    date >>log
    cat err >>log
}

# Log error, if it occurs for first time.
# If this type of error has already been logged then log nothing,
# but wait for $WAIT_ERR seconds.
log-wait () {
    local STATUS="status/$1"
    if [ -f $STATUS ] ; then
        sleep $WAIT_ERR
    else
        touch $STATUS
        log
    fi
}

# Reset error status to ok, so this type of error will be logged again.
status-ok () {
    local STATUS="status/$1"
    rm -f $STATUS
}

# Execute $cmd repeatedly until success.
# Errors are written to file 'err' and logged once.
retry () {
    local cmd=$1
    local STATUS=$2
    while true; do
        $cmd 2>err ||
            # On failure, log once, wait and try again.
            { log-wait $STATUS; continue; }
        status-ok $STATUS
        break
    done
}

# Wait for new jobs on remote server,
# move them from "waiting" to "inprogress",
# copy jobs to "inprogress" on local server.
get-jobs () {
    local JOBS
    while true; do
        JOBS=$(ssh -q $REMOTE <<'EOF' 2>err
# Execute on remote server.
# Abort on every error.
set -e
mkdir -p waiting inprogress finished result tmp

while true; do

    # Check for new jobs in directory "waiting".
    NEW=$(ls waiting)
    if [ -n "$NEW" ] ; then
       # Move new jobs to "inprogress".
       for f in $NEW; do
          mv waiting/$f inprogress/$f
       done
       # Check again, to process multiple incoming jobs together.
       sleep 0.5
       continue
    else

       # Look again, adding stale jobs in directory "inprogress".
       # Show old jobs first.
       JOBS=$(ls -rt inprogress)

       if [ -n "$JOBS" ] ; then
           # Announce found files to STDOUT.
           echo $JOBS
           exit
       fi
       # No jobs found, wait and check again
       sleep 1
    fi
done
EOF
                  ) ||
            # On failure, log once, wait and try again.
            { log-wait ssh-get; continue; }
        status-ok ssh-get
        break
    done
    for JOB in $JOBS; do
        local FILE="inprogress/$JOB"
        local TMP=tmp/$JOB
        retry "scp -q $REMOTE:$FILE $TMP" scp-get
        mv $TMP $FILE
    done
}

# Process finished jobs in "result/":
# - Move job from result/job-id to remote server: result/job-id
# - Remove inprogress/job-id locally and
# - at remote server move inprogress/job-id to finished/job-id.
mark-finished () {
    for JOB in $(ls -rt result/) ; do
        local RESULT=result/$JOB
        local TMP=tmp/$JOB
        local INPROGRESS=inprogress/$JOB
        local FINISHED=finished/$JOB
        retry "scp -q $RESULT $REMOTE:$TMP" scp-put
        retry "ssh -q $REMOTE mv $TMP $RESULT" ssh-mv-result

        # Ignore error if file was already moved before,
        # but still retry, if ssh fails.
        retry "ssh -q $REMOTE mv $INPROGRESS $FINISHED || true" ssh-mv-job
        rm $RESULT
        rm -f $INPROGRESS
    done
}

process () {

    # $1 is exit status from processing of first half of jobs.
    # If this succeeded then processing of second half would fail anyway,
    # if we already know, that some job has errors.
    local WILL_FAIL
    [ $1 -eq 0 ] && WILL_FAIL=1

    # Other arguments are filenames of to be processed jobs.
    shift

    if [ -z "$WILL_FAIL" -o $# -eq 1 ] ; then

        # Apply worker to one or more jobs.
        # Store errors in $STATUS.
        # $STATUS is emtpy on success.
        STATUS=tmp/worker
        $WORKER $* 2>$STATUS ||
            grep -q '[^[:space:]]' $STATUS ||
            echo "Unknown error" > $STATUS

        # On success or if only one job was processed,
        # copy $STATUS to directory "result/",
        # one copy for each job.
        [ ! -s $STATUS ]
        local SUCCESS=$?
        if [ $SUCCESS -eq 0 -o $# -eq 1 ] ; then
            for f in $*; do
                JOB=$(basename $f)
                cp $STATUS result/$JOB
            done
            [ $SUCCESS -eq 0 ]	# Return status.
            return
        fi
    fi

    # An error occurred while multiple jobs have been processed.
    # To find out which job caused the error, recursively process jobs
    # again in two chunks with half the number of jobs.
    local -a H1 H2
    local half=$(($#/2))
    local i=0
    for JOB in $*; do
        if [ $i -lt $half ]; then
            H1+=($JOB)
        else
            H2+=($JOB)
        fi
        ((i++))
    done
    process 1 ${H1[*]}
    local SUCCESS=$?
    process $SUCCESS ${H2[*]}
    [ $? -eq 0 -a $SUCCESS -eq 0 ]	# Return status.
    return
}

mkdir -p inprogress result status tmp
while true; do

    # Process results from below or
    # leftover results from previous run, if script was interrupted.
    mark-finished

    # Wait for new jobs if directory "inprogress/" is empty
    if [ -z "$(ls inprogress)" ] ; then
        get-jobs
    fi

    process 1 $(ls -rt inprogress/*)
done
